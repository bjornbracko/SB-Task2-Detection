# -*- coding: utf-8 -*-
"""Object Detection Using VGG16 With Tensorflow.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/15tA57gXnWprZjc5J_V7591AUdSQWrTF6
"""
import glob
import os
import cv2

import cv2
from tensorflow.keras.preprocessing.image import load_img
# we also save images into array format so import img_array library too
from tensorflow.keras.preprocessing.image import img_to_array



im_list = sorted(glob.glob('data/ears/train/*.png'))
annot = 'data/ears/annotations/detection/YOLO_converted_train/'
data=[]
targets=[]
filenames=[]
for im in im_list:
  filename = im.split('/')[-1]
  image=cv2.imread(im)
  image = load_img(im, target_size=(224, 224))
  image = img_to_array(image)
  annot_name = annot + filename.split('.')[0] + '.txt'
  annots = ()
  with open(annot_name) as f:
    lines = f.readlines()

    for line in lines:
      l_arr = line.split(" ")[1:5]
      l_arr = [float(i) for i in l_arr]
      annots = (l_arr[0], l_arr[1], l_arr[2], l_arr[3])
      break


  targets.append(annots)
  filenames.append(filename)
  data.append(image)

im_list_test = sorted(glob.glob('data/ears/test/*.png'))
annot_test = 'data/ears/annotations/detection/YOLO_converted_test/'
data_test = []
targets_test = []
filenames_test = []

for im in im_list_test:
  filename = im.split('/')[-1]
  image = cv2.imread(im)
  image = load_img(im, target_size=(224, 224))
  image = img_to_array(image)
  annot_name = annot_test + filename.split('.')[0] + '.txt'
  annots = ()
  with open(annot_name) as f:
    lines = f.readlines()

    for line in lines:
      l_arr = line.split(" ")[1:5]
      l_arr = [float(i) for i in l_arr]
      annots = (l_arr[0], l_arr[1], l_arr[2], l_arr[3])
      break

  targets_test.append(annots)
  filenames_test.append(filename)
  data_test.append(image)



# Lets Load Dataset
# airplanes annotation is a Csv file thats why we can see through with rows



# lets make three list where we save our exact bounding boxes


# After load we have to split dataset according to images
# import some usefull libraries


# Normalizing Data here also we face would face issues if we take input as integer
import numpy as np
data=np.array(data,dtype='float32') / 255.0
targets=np.array(targets,dtype='float32')
data_test=np.array(data_test,dtype='float32') / 255.0
targets_test=np.array(targets_test,dtype='float32')

# we should seperate data into train and split so import sklearn library
from sklearn.model_selection import train_test_split

# split into testing and training
#split=train_test_split(data,targets,filenames,test_size=0,random_state=42)


# lets split into steps
#(train_images,_) = split[:2]
#(train_targets,_) = split[2:4]
#(train_filenames,_) = split[4:]

#split=train_test_split(data_test,targets_test,filenames_test,test_size=1,random_state=42)
#(_,test_images) = split[:2]
#(_,test_targets) = split[2:4]
#(_,test_filenames) = split[4:]



# lets import pre trained VGG16 Which is already Builtin for computer vision
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Input

# Imagenet is a competition every year held and VGG16 is winner of between  2013-14
# so here we just want limited layers so thats why we false included_top
vgg=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(224,224,3)))

vgg.summary()

from tensorflow.keras.layers import Input,Flatten,Dense

# we use VGG16 as per our requirement not use whole
vgg.trainable = False

flatten = vgg.output

flatten = Flatten()(flatten)

# Lets make bboxhead
bboxhead = Dense(128,activation="relu")(flatten)
bboxhead = Dense(64,activation="relu")(bboxhead)
bboxhead = Dense(32,activation="relu")(bboxhead)
bboxhead = Dense(4,activation="relu")(bboxhead)

# lets import Model
from tensorflow.keras.models import Model
model = Model(inputs = vgg.input,outputs = bboxhead)

model.summary()

# Lets fit our model
# Optimization
from tensorflow.keras.optimizers import Adam

opt = Adam(1e-4)

model.compile(loss='mse',optimizer=opt)

history = model.fit(data, targets,validation_data=(data_test,targets_test),batch_size=32,epochs=300,verbose=1)

# lets save model
model.save('VGG16_ears.h5')
exit()
